# WizardLM: Empowering Large Language Models to Follow Complex Instructions
[View on arXiv](https://arxiv.org/abs/2304.12244)

## ğŸ“„ Paper 11: â€œWizardLM: Empowering Large Language Models to Follow Complex Instructionsâ€
**Authors**: Xu et al., 2023

### ğŸ” Simple Explanation:
WizardLM fine-tunes large models to follow **multi-step and complex instructions** better. Rather than simple Q&A, it handles tasks like â€œSummarize this, then give me pros/cons, then suggest improvements.â€

They use a method called **evolutionary instruction tuning**â€”taking simple instructions and evolving them into more challenging, multi-step ones.

### ğŸ§  Key Concepts:
- **Instruction-following**: Making LLMs do exactly what you ask.
- **Evolved Instructions**: Automatically making instructions more complex to train the model better.
- **Improved Reasoning**: The model handles more nuanced and structured outputs.

### ğŸ’¡ Real-World Analogy:
Like upgrading your assistant from just answering â€œWhatâ€™s the weather?â€ to: â€œCheck the forecast, summarize changes this week, and recommend clothing for each day.â€

### ğŸ§© Why It Matters:
- Huge boost in instruction-following ability.
- Improves performance on tasks like writing, summarizing, evaluating, planning.
- Used in many open-source model training pipelines (e.g., LLaMA-2/3 instruction-tuned variants).