# Reciprocal Rank Fusion RRF for Document Retrieval
[View Paper](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)

## ğŸ“„ Paper 19: â€œReciprocal Rank Fusion (RRF): Simple Yet Effective Fusion for Document Retrievalâ€
**Authors**: Cormack, Clarke, and Buettcher, 2009

### ğŸ” Simple Explanation:
RRF is a **super simple method for combining multiple ranked lists** (like from different search engines or models) into a single, stronger ranked result.

It turns out that just **averaging the ranks** in a clever way gives you a huge performance boostâ€”no machine learning required.

### ğŸ§  Key Concepts:
- **Reciprocal Rank**: If an item is ranked #1, its score is `1/(k + rank)`, where `k` is a small constant (usually 60).
- **Fusion**: Combine scores from multiple ranked lists by summing these reciprocal ranks.
- **Robust to Noise**: Even if one list is bad, good signals from other lists dominate.

### ğŸ“Š Example:
Suppose three models return a document ranked:
- #2 in list A â†’ `1 / (60 + 2)`  
- #5 in list B â†’ `1 / (60 + 5)`  
- Not in list C â†’ 0  

Add the scores, and now you have a smart combined ranking.

### ğŸ’¡ Real-World Analogy:
Imagine asking three friends to recommend restaurants. One says â€œgo to Bento,â€ another says â€œmaybe try Ramen,â€ and the third is indecisive. You donâ€™t just pick oneâ€”you consider the **consensus**, weighted by enthusiasm. Thatâ€™s RRF.

### ğŸ§© Why It Matters:
- **Extremely effective**â€”often outperforms individual retrieval models
- **Used in modern hybrid search pipelines** (e.g. vector + keyword fusion)
- Great baseline and component for **retrieval systems**, **search engines**, and **RAG pipelines**