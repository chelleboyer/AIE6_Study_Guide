# Principled Instructions Are All You Need

Principled Instructions Are All You Need

Link to paper: https://arxiv.org/abs/2312.16171


## ğŸ“„ Paper 4: â€œPrincipled Instructions Are All You Needâ€
**Authors**: Zhou et al., 2023

### ğŸ” Simple Explanation:
This paper explores **how the *quality* of your instructions** impacts an LLM's performanceâ€”and it turns out **clear, structured prompts work better** than short or vague ones.

### ğŸ§  Key Concepts:
- **Principled Instructions** are:
  - **Explicit**: Tell the model exactly what to do  
  - **Structured**: Use numbered steps, headers, or bullet points  
  - **Contextualized**: Give examples or background where needed  

### âœï¸ Example:
**Weak Prompt**: â€œSummarize this.â€  
**Principled Prompt**: â€œSummarize the article in 3 bullet points. Focus on the main argument, supporting evidence, and conclusion.â€

### ğŸ’¡ Real-World Analogy:
Itâ€™s the difference between telling someone â€œgo clean the houseâ€ versus giving them a checklist: â€œ1. Vacuum the carpet. 2. Wipe the counters. 3. Take out the trash.â€ Which one do you think works better?

### ğŸ§© Why It Matters:
- Crucial for **prompt engineering** and **evaluating LLM apps**  
- Helps builders design **reliable interfaces** between users and models