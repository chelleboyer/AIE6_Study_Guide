# Principled Instructions Are All You Need

Principled Instructions Are All You Need

Link to paper: https://arxiv.org/abs/2312.16171


## 📄 Paper 4: “Principled Instructions Are All You Need”
**Authors**: Zhou et al., 2023

### 🔍 Simple Explanation:
This paper explores **how the *quality* of your instructions** impacts an LLM's performance—and it turns out **clear, structured prompts work better** than short or vague ones.

### 🧠 Key Concepts:
- **Principled Instructions** are:
  - **Explicit**: Tell the model exactly what to do  
  - **Structured**: Use numbered steps, headers, or bullet points  
  - **Contextualized**: Give examples or background where needed  

### ✍️ Example:
**Weak Prompt**: “Summarize this.”  
**Principled Prompt**: “Summarize the article in 3 bullet points. Focus on the main argument, supporting evidence, and conclusion.”

### 💡 Real-World Analogy:
It’s the difference between telling someone “go clean the house” versus giving them a checklist: “1. Vacuum the carpet. 2. Wipe the counters. 3. Take out the trash.” Which one do you think works better?

### 🧩 Why It Matters:
- Crucial for **prompt engineering** and **evaluating LLM apps**  
- Helps builders design **reliable interfaces** between users and models